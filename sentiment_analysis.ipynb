{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Final Project: Sentiment Analysis (Fall 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group Members**\n",
    "\n",
    "* Amit Sarvate (100794129)\n",
    "* Nirujan Velvarathan (100706828)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "* We aim to classify movie reviews into positive or negative sentiments using a large, popular dataset containing 50,000 instances. \n",
    "* To achieve this, we will experiment with three different network architectures: \n",
    "    * a Feedforward Neural Network with pre-trained embeddings, \n",
    "    * a Convolutional Neural Network (CNN), \n",
    "    * and a Gated Recurrent Unit (GRU). \n",
    "* The goal is to compare their performance on sentiment classification and identify the most effective model. \n",
    "* Additionally, we will develop an application where users can input a review and receive a sentiment prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim import corpora\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    PATH_TO_DATASET = \"data/IMDB Dataset.csv\"\n",
    "\n",
    "    df = pd.read_csv(PATH_TO_DATASET)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_df(dataframe):\n",
    "    # tokenize text \n",
    "    dataframe['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in dataframe['review']] \n",
    "\n",
    "    # stemmed tokens \n",
    "    porter_stemmer = PorterStemmer()\n",
    "    dataframe['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in dataframe['tokenized_text'] ]\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(dataframe, test_size=0.3, shuffle_state=True):\n",
    "    \n",
    "    # Specify the features and target columns\n",
    "    features = ['review', 'tokenized_text', 'stemmed_tokens']\n",
    "    target = 'sentiment'\n",
    "    \n",
    "    # Perform train-test split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        dataframe[features],\n",
    "        dataframe[target],\n",
    "        shuffle=shuffle_state,\n",
    "        test_size=test_size,\n",
    "        random_state=15\n",
    "    )\n",
    "    \n",
    "    # Display value counts for sentiments\n",
    "    print(\"Value counts for Train sentiments\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test sentiments\")\n",
    "    print(Y_test.value_counts())\n",
    "    \n",
    "    # Reset indices for clean DataFrame manipulation\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    Y_train = Y_train.reset_index(drop=True)\n",
    "    Y_test = Y_test.reset_index(drop=True)\n",
    "    \n",
    "    # Print debug information\n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    print(X_train.head())\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(dataframe, padding=True):\n",
    "    if padding:\n",
    "        print(\"Dictionary with padded token added\")\n",
    "        review_dict = corpora.Dictionary([['pad']])\n",
    "        review_dict.add_documents(dataframe['stemmed_tokens'])\n",
    "    else:\n",
    "        print(\"Dictionary without padding\")\n",
    "        review_dict = corpora.Dictionary(dataframe['stemmed_tokens'])\n",
    "    return review_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(review_dict, sentence):\n",
    "    vec = torch.zeros(VOCAB_SIZE, dtype=torch.float64, device=device)\n",
    "    for word in sentence:\n",
    "        vec[review_dict.token2id[word]] += 1\n",
    "    return vec.view(1, -1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(label):\n",
    "    if label == -1:\n",
    "        return torch.tensor([0], dtype=torch.long, device=device)\n",
    "    elif label == 0:\n",
    "        return torch.tensor([1], dtype=torch.long, device=device)\n",
    "    else:\n",
    "        return torch.tensor([2], dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution of Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pre_process_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Train sentiments\n",
      "sentiment\n",
      "negative    17512\n",
      "positive    17488\n",
      "Name: count, dtype: int64\n",
      "Value counts for Test sentiments\n",
      "sentiment\n",
      "positive    7512\n",
      "negative    7488\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "                                              review  \\\n",
      "0  The sequel is exactly what you will expect it ...   \n",
      "1  This is a pretty well known one so i won't get...   \n",
      "2  I made the mistake of buying this since I coll...   \n",
      "3  This movie is the proverbial 80s flick that sh...   \n",
      "4  I absolutely LOVED this movie as a child. I ca...   \n",
      "\n",
      "                                      tokenized_text  \\\n",
      "0  [the, sequel, is, exactly, what, you, will, ex...   \n",
      "1  [this, is, pretty, well, known, one, so, won, ...   \n",
      "2  [made, the, mistake, of, buying, this, since, ...   \n",
      "3  [this, movie, is, the, proverbial, flick, that...   \n",
      "4  [absolutely, loved, this, movie, as, child, ca...   \n",
      "\n",
      "                                      stemmed_tokens  \n",
      "0  [the, sequel, is, exactli, what, you, will, ex...  \n",
      "1  [thi, is, pretti, well, known, on, so, won, ge...  \n",
      "2  [made, the, mistak, of, bui, thi, sinc, collec...  \n",
      "3  [thi, movi, is, the, proverbi, flick, that, sh...  \n",
      "4  [absolut, love, thi, movi, as, child, can, see...  \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = split_train_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary without padding\n"
     ]
    }
   ],
   "source": [
    "review_dict = make_dict(df, padding=False)\n",
    "\n",
    "VOCAB_SIZE = len(review_dict)\n",
    "\n",
    "input_dim = VOCAB_SIZE\n",
    "hidden_dim = 500\n",
    "output_dim = 3\n",
    "num_epochs = 100\n",
    "\n",
    "reload(models)\n",
    "ff_nn_bow_model = models.FeedforwardNeuralNetwork(input_dim, hidden_dim, output_dim)\n",
    "ff_nn_bow_model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(ff_nn_bow_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
